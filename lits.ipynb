{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "impor torch.utils.data as DAta\n",
    "from glob import glob\n",
    "import pydicom\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import matplitlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperParam:\n",
    "    def __init__(self):\n",
    "        self.datasetMode = 1 #1 = InPhase, 2 = OutPhase, 3 = T2, 4 = In+OutPhase (Not Implimented yet)\n",
    "        #self.interpFactor = None\n",
    "        self.interpFactor = (0.5,0.5,0.5)\n",
    "        self.runName = '3DWNetv2'\n",
    "        self.combineLoss = False\n",
    "        #network configure\n",
    "        #self.ModelDownscale = True\n",
    "        self.ModelDownscale = False\n",
    "        self.InputCh=1\n",
    "        self.ScaleRatio = 2\n",
    "        self.ConvSize = 3\n",
    "        self.pad = (self.ConvSize - 1) // 2 \n",
    "        self.MaxLv = 5\n",
    "        self.ChNum = [self.InputCh,64]\n",
    "        for i in range(self.MaxLv-1):\n",
    "            self.ChNum.append(self.ChNum[-1]*2)\n",
    "        #data configure\n",
    "        self.BatchSize = 1\n",
    "        self.Shuffle = False\n",
    "        self.LoadThread = 0\n",
    "        self.inputsize = [224,224]\n",
    "        #partition configure\n",
    "        self.K = 10\n",
    "        #training configure\n",
    "        self.init_lr = 0.001\n",
    "        self.lr_decay = 0.1\n",
    "        self.lr_decay_iter = 5\n",
    "        self.max_iter = 100\n",
    "        self.checkpoint_frequency = 10\n",
    "        self.cuda_dev = 0 \n",
    "        self.cuda_dev_list = \"4,5\"\n",
    "        self.check_iter = 1000\n",
    "        self.useSSIMLoss = True\n",
    "        #self.model_tested = \"checkpoints/checkpoint_8_8_2_44_epoch_50\"\n",
    "        #self.model_tested = \"/Users/dhanunjayamitta/Downloads/pretrained/checkpoint_3DWNetv2_SepLoss_ds2_ep100_epoch_100\"\n",
    "        self.model_tested = \"checkpoints/checkpoint_9_16_17_8_epoch_990\"\n",
    "        #Ncuts Loss configure\n",
    "        self.radius = 4\n",
    "        self.sigmaI = 10\n",
    "        self.sigmaX = 4\n",
    "\n",
    "    def initiate(self):\n",
    "        #pre-calculations\n",
    "        if self.combineLoss:\n",
    "            self.runName += '_CombLoss'\n",
    "        else:\n",
    "            self.runName += '_SepLoss'\n",
    "        self.runName += '_ds'+str(self.datasetMode)+'_ep'+str(self.max_iter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = hyperParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdomenDS(Data.Dataset):\n",
    "    \"\"\"description of class\"\"\"\n",
    "\n",
    "    def __init__(self, path, mode, ds_mode, interp_fact=None, readGT=False):\n",
    "        self.mode = mode\n",
    "        print('ds mode: '+ str(ds_mode))\n",
    "        self.listOfItems = glob(path+\"/*\")\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        if self.is_cuda:\n",
    "            import cupy as cp\n",
    "            self.numpack = cp\n",
    "        else:\n",
    "            self.numpack = np\n",
    "        self.interp_fact = interp_fact\n",
    "        self.GetVols(ds_mode, readGT=readGT)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"For returning the length of the dataset\"\"\"\n",
    "        return len(self.listOfItemVols)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.listOfItemVols[index]\n",
    "\n",
    "    def GetVols(self, ds_mode, normalize = True, readGT=False):\n",
    "        #ds_mode: 1 = InPhase, 2 = OutPhase, 3 = T2, 4 = In+OutPhase (Not Implimented yet)\n",
    "        self.listOfItemVols = []\n",
    "        for index in range(len(self.listOfItems)):\n",
    "            if \"30\" in self.listOfItems[index]:\n",
    "                print('ignored 30 because of its size is too big for GPU')\n",
    "                continue\n",
    "            if ds_mode == 1:\n",
    "                self.lstFilesDCM = sorted(glob(self.listOfItems[index]+\"**/T1DUAL/DICOM_anon/InPhase/*\"))\n",
    "                self.lstFilesGround = sorted(glob(self.listOfItems[index]+\"**/T1DUAL/Ground/*\"))\n",
    "            elif ds_mode == 2:\n",
    "                self.lstFilesDCM = sorted(glob(self.listOfItems[index]+\"**/T1DUAL/DICOM_anon/OutPhase/*\"))\n",
    "                self.lstFilesGround = sorted(glob(self.listOfItems[index]+\"**/T1DUAL/Ground/*\"))\n",
    "            elif ds_mode == 3:\n",
    "                self.lstFilesDCM = sorted(glob(self.listOfItems[index]+\"**/T2SPIR/DICOM_anon/*\"))\n",
    "                self.lstFilesGround = sorted(glob(self.listOfItems[index]+\"**/T2SPIR/Ground/*\"))\n",
    "            else:\n",
    "                print('Invalid or Not Implimented ds_mode')\n",
    "            print(self.listOfItems[index])\n",
    "            dicoms = []\n",
    "            for ite in self.lstFilesDCM:\n",
    "                #print(ite)\n",
    "                RefDs = pydicom.read_file(ite)\n",
    "                pixels = RefDs.pixel_array\n",
    "                dicoms.append(pixels)  \n",
    "            dicoms = np.asarray(dicoms)\n",
    "\n",
    "            if len(dicoms.shape) == 3:\n",
    "                if self.interp_fact is not None:\n",
    "                    tensor = torch.from_numpy(np.expand_dims(np.expand_dims(dicoms, 0), 0)/1.0).float()\n",
    "                    dicoms = torch.nn.functional.interpolate(tensor, scale_factor=self.interp_fact, mode='nearest').numpy()\n",
    "                    dicoms = np.squeeze(dicoms, (0,1))\n",
    "                dicoms = np.expand_dims(dicoms, 0)\n",
    "                if normalize:\n",
    "                    dicoms = dicoms/dicoms.max()\n",
    "            \n",
    "                if readGT:\n",
    "                    gtvols = []\n",
    "                    for ite in self.lstFilesGround:\n",
    "                        #print(ite)\n",
    "                        gt = cv2.imread(ite,0)\n",
    "                        gtvols.append(gt)                \n",
    "                    gtvols = np.asarray(gtvols)\n",
    "                    gt_uniq = np.unique(gtvols)\n",
    "                    gt_processed = np.zeros((len(gt_uniq),gtvols.shape[0],gtvols.shape[1], gtvols.shape[2]))\n",
    "                    for i in range(len(gt_uniq)):\n",
    "                        gt_processed[i,gtvols == gt_uniq[i]] = 1\n",
    "                    if self.interp_fact is not None:\n",
    "                        tensor = torch.from_numpy(np.expand_dims(gt_processed, 0)/1.0).float()\n",
    "                        gt_processed = torch.nn.functional.interpolate(tensor, scale_factor=self.interp_fact, mode='nearest').numpy()\n",
    "                        gt_processed = np.squeeze(gt_processed, 0)\n",
    "                    self.listOfItemVols.append((torch.from_numpy(dicoms/1.0).float(), torch.from_numpy(gt_processed/1.0).float()))\n",
    "                else:\n",
    "                    if(self.mode == \"train\"):    \n",
    "                        #dicoms = np.expand_dims(dicoms,0)            \n",
    "                        weight = self.cal_weight(dicoms)   \n",
    "                        self.listOfItemVols.append((torch.from_numpy(dicoms/1.0).float(), torch.from_numpy(weight/1.0).float()))\n",
    "                    else:\n",
    "                        dicoms = np.expand_dims(dicoms, 0)\n",
    "                        self.listOfItemVols.append(torch.from_numpy(dicoms/1.0).float())\n",
    "            else:\n",
    "                print('ERROR: DICOM shape error for '+ self.listOfItems[index] + ' shape found : ' + str(dicoms.shape))\n",
    "\n",
    "\n",
    "    def cal_weight(self, raw_data):\n",
    "        data = self.numpack.asarray(raw_data)\n",
    "        shape = data.shape\n",
    "        #print(\"calculating weights.\")\n",
    "        dissim = self.numpack.zeros((shape[0],shape[1],shape[2],shape[3],(config.radius-1)*2+1,(config.radius-1)*2+1,(config.radius-1)*2+1))\n",
    "        padded_data = self.numpack.pad(data,((0,0),(config.radius-1,config.radius-1),(config.radius-1,config.radius-1),(config.radius-1,config.radius-1)),'reflect')\n",
    "        for m in range(2*(config.radius-1)+1):\n",
    "            for n in range(2*(config.radius-1)+1):\n",
    "                for i in range(2*(config.radius-1)+1):\n",
    "                    dissim[:,:,:,:,m,n,i] = data-padded_data[:,m:shape[1]+m,n:shape[2]+n,i:shape[3]+i]\n",
    "        temp_dissim = self.numpack.exp(-self.numpack.power(dissim,2).sum(0,keepdims = True)/config.sigmaI**2)  \n",
    "        dist = self.numpack.zeros((2*(config.radius-1)+1,2*(config.radius-1)+1,2*(config.radius-1)+1))\n",
    "        for m in range(1-config.radius,config.radius):\n",
    "            for n in range(1-config.radius,config.radius):\n",
    "                for i in range(1-config.radius,config.radius):\n",
    "                    if m**2+n**2+i**2<config.radius**2:\n",
    "                        dist[m+config.radius-1,n+config.radius-1,i+config.radius-1] = self.numpack.exp(-(m**2+n**2+i**2)/config.sigmaX**2)\n",
    "        print(\"weight calculated.\")\n",
    "        res = self.numpack.multiply(temp_dissim,dist)\n",
    "        if self.is_cuda:\n",
    "            weight = self.numpack.asnumpy(res)\n",
    "        else:\n",
    "            weight = np.asarray(res)   \n",
    "        del data, shape, dissim, padded_data, temp_dissim, dist, res\n",
    "        if self.is_cuda:\n",
    "            self.numpack.get_default_memory_pool().free_all_blocks()\n",
    "            self.numpack.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        return weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
